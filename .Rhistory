library(tidyverse)
# Install NSNSDAcoustics package
#devtools::install_github('nationalparkservice/NSNSDAcoustics')
library(NSNSDAcoustics)
gitcreds::gitcreds_set()
library(bslib)
library(usethis)
library(devtools)
install.packages('bslib')
install.packages("bslib")
install.packages('usethis')
install.packages('devtools')
devtools::install_github('nationalparkservice/NSNSDAcoustics')
# Install NSNSDAcoustics package
#devtools::install_github('nationalparkservice/NSNSDAcoustics')
library(NSNSDAcoustics)
library(tidyverse)
# Update this for each site
base_path <- "D:/Science and Faith Audio Files/LibertyGrace/Back_LGB1"
# Function to get deployment folders
get_deployment_folders <- function(base_path) {
deployments <- list.dirs(base_path, recursive = FALSE)
deployment_dates <- list()
for (deployment in deployments) {
dates <- list.dirs(deployment, recursive = FALSE)
deployment_dates <- c(deployment_dates, dates)
}
return(deployment_dates)
}
# Get deployment folders
all_deployments <- get_deployment_folders(base_path)
all_results_p1 <- data.frame()
# Process each deployment
for (deployment in all_deployments) {
results_path <- file.path(deployment, "results_formatted")
# Check if the results folder exists
if (dir.exists(results_path)) {
# Gather results for this deployment
formatted_results <- birdnet_gather(results.directory = results_path, formatted = TRUE)
# Add deployment info
formatted_results$deployment <- basename(deployment)
# Append to all_results_p2
all_results_p1 <- rbind(all_results_p1, formatted_results)
}
}
# Fix resultspath names
all_results_p1$resultspath <- sub(
"(.*\\\\SD_[AB]\\\\)(\\d{8}\\\\)(.*)",
"\\1\\2results_formatted\\\\\\3",
sub("\\.WAV$", ".BirdNET_formatted_results.csv", all_results_p1$filepath)
)
# Specify drive letters if changed by the code above
all_results_p1$filepath <- sub("^.:", "D:", all_results_p1$filepath)
all_results_p1$resultspath <- sub("^.:", "D:", all_results_p1$resultspath)
rm(formatted_results)
# Filter by confidence >= 0.1 (also removes NAs)
filt_p1_1 <- all_results_p1[all_results_p1$confidence >= 0.1, ]
# Create empty data frame for all results
all_results_p2 <- data.frame()
# Process each deployment
for (deployment in all_deployments) {
results_path2 <- file.path(deployment, "results_pass2_formatted")
# Check if the results folder exists
if (dir.exists(results_path2)) {
# Gather results for this deployment
formatted_results <- birdnet_gather(results.directory = results_path2, formatted = TRUE)
# Add deployment info
formatted_results$deployment <- basename(deployment)
# Append to all_results_p2
all_results_p2 <- rbind(all_results_p2, formatted_results)
}
}
# Fix resultspath names
all_results_p2$resultspath <- sub(
"(.*\\\\SD_[AB]\\\\)(\\d{8}\\\\)(.*)",
"\\1\\2results_pass2_formatted\\\\\\3",
sub("\\.WAV$", ".BirdNET_formatted_results.csv", all_results_p2$filepath)
)
# Specify drive letters if changed by the code above
all_results_p2$filepath <- sub("^.:", "F:", all_results_p2$filepath)
all_results_p2$resultspath <- sub("^.:", "F:", all_results_p2$resultspath)
rm(formatted_results)
# Filter by confidence >= 0.1 (also removes NAs)
filt_p2_1 <- all_results_p2[all_results_p2$confidence >= 0.1, ]
# Count # of observations of each species at confidence >= 0.1
#species_p2 <- count(filt_p2_1, filt_p2_1$common_name, sort = TRUE)
1+1
# make a vector filt_g.1 with all the filepaths w/ a human vocal detection
filt_g.1 <- filt_p1_1 %>%
filter(scientific_name == 'Human vocal') %>%
distinct(filepath) %>%
pull(filepath)
# filter filt.1 to keep only the filepaths without human vocal detection
filt_h.1 <- filt_p2_1 %>%
filter(!filepath %in% filt_g.1)
rm(filt_g.1, filt_p1_1, filt_p2_1) # cleanup
## Validate Results --------------------------------------------------------
# Create a random sample of N detections to verify
set.seed(4)
to_verify <- filt_h.1[common_name == "Carolina Chickadee"|common_name == "Black-capped Chickadee"][sample(.N, 50)]
set.seed(4)
to_verify <- filt_h.1[common_name == "Carolina Chickadee"|common_name == "Black-capped Chickadee"][sample(.N, 50)]
View(to_verify)
# Create a verification library
ver_lib <- c('y', 'n', 'unsure')
# Set directories for audio and results
audio_directories <- dirname(to_verify$filepath)
results_directories <- dirname(to_verify$resultspath)
# Create list to hold validation results
verification_results <- vector("list", nrow(to_verify))
# Note: having a project open will ensure you don't have to hunt down each temp audio file
setwd("C:/Users/kirchgrabera/Smithsonian Dropbox/Aidan Kirchgraber/Science and Faith/Aidan/audiomoth_project_Julia")
# Note: having a project open will ensure you don't have to hunt down each temp audio file
setwd("C:\Users\aidan\Smithsonian Dropbox\Aidan Kirchgraber\Science and Faith\Aidan\audiomoth_project_Julia")
# Note: having a project open will ensure you don't have to hunt down each temp audio file
setwd("C:/Users/aidan/Smithsonian Dropbox/Aidan Kirchgraber/Science and Faith/Aidan/audiomoth_project_Julia")
## birdnet_verify ##
for (i in 1:nrow(to_verify)) {
detection <- to_verify[i, ]
verification_results[[i]] <- birdnet_verify(data = detection,
verification.library = ver_lib,
audio.directory = audio_directories[i],
results.directory = results_directories[i],
overwrite = TRUE,
play = TRUE,
frq.lim = c(0, 12),
buffer = 1,
box.col = 'blue',
spec.col = monitoR::gray.3())
}
View(to_verify)
# Specify drive letters if changed by the code above
all_results_p2$filepath <- sub("^.:", "D:", all_results_p2$filepath)
all_results_p2$resultspath <- sub("^.:", "D:", all_results_p2$resultspath)
# Filter by confidence >= 0.1 (also removes NAs)
filt_p2_1 <- all_results_p2[all_results_p2$confidence >= 0.1, ]
# make a vector filt_g.1 with all the filepaths w/ a human vocal detection
filt_g.1 <- filt_p1_1 %>%
filter(scientific_name == 'Human vocal') %>%
distinct(filepath) %>%
pull(filepath)
base_path <- "D:/Science and Faith Audio Files/LibertyGrace/Back_LGB1"
# Function to get deployment folders
get_deployment_folders <- function(base_path) {
deployments <- list.dirs(base_path, recursive = FALSE)
deployment_dates <- list()
for (deployment in deployments) {
dates <- list.dirs(deployment, recursive = FALSE)
deployment_dates <- c(deployment_dates, dates)
}
return(deployment_dates)
}
# Get deployment folders
all_deployments <- get_deployment_folders(base_path)
## First pass results ------------------------------------------------------
# for scrubbing human voices
all_results_p1 <- data.frame()
# Process each deployment
for (deployment in all_deployments) {
results_path <- file.path(deployment, "results_formatted")
# Check if the results folder exists
if (dir.exists(results_path)) {
# Gather results for this deployment
formatted_results <- birdnet_gather(results.directory = results_path, formatted = TRUE)
# Add deployment info
formatted_results$deployment <- basename(deployment)
# Append to all_results_p2
all_results_p1 <- rbind(all_results_p1, formatted_results)
}
}
# Fix resultspath names
all_results_p1$resultspath <- sub(
"(.*\\\\SD_[AB]\\\\)(\\d{8}\\\\)(.*)",
"\\1\\2results_formatted\\\\\\3",
sub("\\.WAV$", ".BirdNET_formatted_results.csv", all_results_p1$filepath)
)
# Specify drive letters if changed by the code above
all_results_p1$filepath <- sub("^.:", "D:", all_results_p1$filepath)
all_results_p1$resultspath <- sub("^.:", "D:", all_results_p1$resultspath)
rm(formatted_results)
# Filter by confidence >= 0.1 (also removes NAs)
filt_p1_1 <- all_results_p1[all_results_p1$confidence >= 0.1, ]
## Second pass results -----------------------------------------------------
# Create empty data frame for all results
all_results_p2 <- data.frame()
# Process each deployment
for (deployment in all_deployments) {
results_path2 <- file.path(deployment, "results_pass2_formatted")
# Check if the results folder exists
if (dir.exists(results_path2)) {
# Gather results for this deployment
formatted_results <- birdnet_gather(results.directory = results_path2, formatted = TRUE)
# Add deployment info
formatted_results$deployment <- basename(deployment)
# Append to all_results_p2
all_results_p2 <- rbind(all_results_p2, formatted_results)
}
}
# Fix resultspath names
all_results_p2$resultspath <- sub(
"(.*\\\\SD_[AB]\\\\)(\\d{8}\\\\)(.*)",
"\\1\\2results_pass2_formatted\\\\\\3",
sub("\\.WAV$", ".BirdNET_formatted_results.csv", all_results_p2$filepath)
)
# Specify drive letters if changed by the code above
all_results_p2$filepath <- sub("^.:", "D:", all_results_p2$filepath)
all_results_p2$resultspath <- sub("^.:", "D:", all_results_p2$resultspath)
rm(formatted_results)
# Filter by confidence >= 0.1 (also removes NAs)
filt_p2_1 <- all_results_p2[all_results_p2$confidence >= 0.1, ]
# Count # of observations of each species at confidence >= 0.1
#species_p2 <- count(filt_p2_1, filt_p2_1$common_name, sort = TRUE)
1+1
## Human Voice Scrubbing ---------------------------------------------------
# TODO : have filt_h.1 pull filepath-start/end combos to limit loss of detections for validation
# make a vector filt_g.1 with all the filepaths w/ a human vocal detection
filt_g.1 <- filt_p1_1 %>%
filter(scientific_name == 'Human vocal') %>%
distinct(filepath) %>%
pull(filepath)
# filter filt.1 to keep only the filepaths without human vocal detection
filt_h.1 <- filt_p2_1 %>%
filter(!filepath %in% filt_g.1)
rm(filt_g.1, filt_p1_1, filt_p2_1) # cleanup
## Validate Results --------------------------------------------------------
# Create a random sample of N detections to verify
# NOCA - DONE
# AMRO - DONE
# CARW - DONE
# TUTI - LG
# CACH -
# AGOL -
# RBWO -
# BLJA -
set.seed(4)
#to_verify <- filt_h.1[common_name == "Tufted Titmouse"][sample(.N, 50)]
to_verify <- filt_h.1[common_name == "Carolina Chickadee"|common_name == "Black-capped Chickadee"][sample(.N, 50)]
# Create a verification library
ver_lib <- c('y', 'n', 'unsure')
# Set directories for audio and results
audio_directories <- dirname(to_verify$filepath)
results_directories <- dirname(to_verify$resultspath)
# Create list to hold validation results
verification_results <- vector("list", nrow(to_verify))
# Note: having a project open will ensure you don't have to hunt down each temp audio file
setwd("C:/Users/aidan/Smithsonian Dropbox/Aidan Kirchgraber/Science and Faith/Aidan/audiomoth_project_Julia")
## birdnet_verify ##
for (i in 1:nrow(to_verify)) {
detection <- to_verify[i, ]
verification_results[[i]] <- birdnet_verify(data = detection,
verification.library = ver_lib,
audio.directory = audio_directories[i],
results.directory = results_directories[i],
overwrite = TRUE,
play = TRUE,
frq.lim = c(0, 12),
buffer = 1,
box.col = 'blue',
spec.col = monitoR::gray.3())
}
rm(list=ls())
library(ggplot2)
theme_set(theme_bw())
#Load all microclimate data (24 hr time series)
# ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_july_2024_24hrs_07.26.24.csv")
ddat <- read.csv("C:/Users/kirchgrabera/Smithsonian Dropbox/Aidan Kirchgraber/Science and Faith/Aidan/audio_analysis/birdnet/Data/drop_data_may_sept_2024_24hrs_11.10.24.csv")
#Load all microclimate data (24 hr time series)
# ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_july_2024_24hrs_07.26.24.csv")
ddat <- read.csv("Data/drop_data_may_sept_2024_24hrs_11.10.24.csv")
meta_dat <- read.csv("audiomoth_data_2024/SciFaith_Drop_metadata.csv")
meta_dat <- read.csv("Data/audiomoth_data_2024/SciFaith_Drop_metadata.csv")
#Load metadata files
getwd()
meta_dat <- read.csv("Data/audiomoth_data_2024/SciFaith_Drop_metadata.csv")
rm(list=ls())
library(ggplot2)
theme_set(theme_bw())
#Load all microclimate data (24 hr time series)
# ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_july_2024_24hrs_07.26.24.csv")
ddat <- read.csv("Data/drop_data_may_sept_2024_24hrs_11.10.24.csv")
#Load all microclimate data (24 hr time series)
# ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_july_2024_24hrs_07.26.24.csv")
ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_sept_2024_24hrs_11.10.24.csv")
#Load microclimate summary data (means, max, min, etc)
#ddat_sum <- read.csv("Data/cleaned_drop_data/drop_data_2024_daytime_summaries_07.26.24.csv")
ddat_sum <- read.csv("Data/cleaned_drop_data/drop_data_2024_day_night_summaries_11.23.24.csv")
#Load weather station data
#Data downloaded from here (selected Daily summaries): https://www.ncei.noaa.gov/cdo-web/
#wdat <- read.csv("./Data/weather_station_data/annapolis_naval_acad_2000_2023_daily_11.6.23.csv")
#Data from Baltimore
wdat_bmore <- read.csv("Data/weather_station_data/baltimore_md_sci_ctr_2000_2024_daily_11.22.24.csv")
#Data from Annapolis
wdat_annap <- read.csv("Data/weather_station_data/annapolis_naval_acad_2000_2024_daily_11.22.24.csv")
rm(list=ls())
library(ggplot2)
theme_set(theme_bw())
#Load all microclimate data (24 hr time series)
# ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_july_2024_24hrs_07.26.24.csv")
ddat <- read.csv("Data/cleaned_drop_data/drop_data_may_sept_2024_24hrs_11.10.24.csv")
dim(ddat) #303402  24
#Load microclimate summary data (means, max, min, etc)
#ddat_sum <- read.csv("Data/cleaned_drop_data/drop_data_2024_daytime_summaries_07.26.24.csv")
ddat_sum <- read.csv("Data/cleaned_drop_data/drop_data_2024_day_night_summaries_11.23.24.csv")
dim(ddat_sum) #4042  21
#Data from Baltimore
wdat_bmore <- read.csv("Data/weather_station_data/baltimore_md_sci_ctr_2000_2024_daily_11.22.24.csv")
dim(wdat_bmore) #8425  24
#Data from Annapolis
wdat_annap <- read.csv("Data/weather_station_data/annapolis_naval_acad_2000_2024_daily_11.22.24.csv")
dim(wdat_annap) #8408  25
library(lubridate)
colnames(ddat)
str(ddat)
ddat$datetime2 <- ddat$datetime
summary(is.na(ddat$datetime2)) #No NAs
#ddat$datetime = as.POSIXct(ddat$datetime2, format='%Y-%m-%d %H:%M:%S')
#ddat$datetime <- parse_date_time(ddat$date_time, '%Y-%m-%d %H:%M:%S %p') -- old solution, creates NAs
ddat$datetime <- parse_date_time(ddat$date_time,
orders = c('mdy HM',
'Ymd HMS p'))
summary(is.na(ddat$datetime)) #No NAs
summary(as.character(ddat$datetime) == ddat$datetime2) #All match
test <-  ddat$datetime == ddat$datetime2
head(ddat)
#reformat time elements
drop_dt <- lapply(drop_dt, function(x) cbind(x, hour = as.POSIXlt(x$datetime)$hour))
drop_dt <- lapply(drop_dt, function(x) cbind(x, minute = as.POSIXlt(x$datetime)$min))
drop_dt <- lapply(drop_dt, function(x) cbind(x, month = as.POSIXlt(x$datetime)$mon+1))
drop_dt <- lapply(drop_dt, function(x) cbind(x, day = day(as.POSIXlt(x$datetime))))
drop_dt <- lapply(drop_dt, function(x) cbind(x, date = as.POSIXct(strftime(x$datetime, format="%Y-%m-%d"))))
drop_dt <- lapply(drop_dt, function(x) cbind(x, time = format(as.POSIXct(x$datetime), format = "%H:%M")))
wdat_annap_24$ext_tmax <- ifelse(
wdat_annap_24$month == 5 & wdat_annap_24$TMAX >= 29.64382, 1,
ifelse(wdat_annap_24$month == 6 & wdat_annap_24$TMAX >= 32.75243, 1,
ifelse(wdat_annap_24$month == 7 & wdat_annap_24$TMAX >= 34.29692, 1,
ifelse(wdat_annap_24$month == 8 & wdat_annap_24$TMAX >= 33.19557, 1,
ifelse(wdat_annap_24$month == 9 & wdat_annap_24$TMAX >= 30.91056, 1,
0)
)
)
)
)
